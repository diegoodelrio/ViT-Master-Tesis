{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNeXgrZA0oOvrigSq3nhqIn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Test de estres. El objetivo es evaluar el modelo bajo tres escenarios: Sin oclusion, oclusion moderada (parches del 25%) y oclusion severa (parches 50%)"],"metadata":{"id":"RqBalL09xjbV"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader\n","import os\n","from google.colab import drive"],"metadata":{"id":"hc_-JvQ10LJZ","executionInfo":{"status":"ok","timestamp":1769273236991,"user_tz":-60,"elapsed":12386,"user":{"displayName":"diego del rio","userId":"13207948646283268583"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#Cargar el modelo entrenado\n","#1. Configuracion\n","drive.mount('/content/drive')\n","\n","DATA_DIR = '/content/drive/MyDrive/Master Thesis/Data/Split_Dataset'\n","Save_Path = '/content/drive/MyDrive/Master Thesis/Models/vit_archivtecture_model.pth'\n","\n","#Crear carpeta de modelos si no existe\n","os.makedirs(os.path.dirname(Save_Path), exist_ok=True)\n","\n","#Configuracion de dispositivos\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Ejectuando en: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xzw9tCA0KyW","executionInfo":{"status":"ok","timestamp":1769273266470,"user_tz":-60,"elapsed":21959,"user":{"displayName":"diego del rio","userId":"13207948646283268583"}},"outputId":"98fd0237-676a-45d2-f905-4d82cc879c4a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Ejectuando en: cuda\n"]}]},{"cell_type":"code","source":["#Definir transformaciones y dataloader\n","val_transforms = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","val_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'val'), val_transforms)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","class_names = val_dataset.classes\n","num_classes = len(class_names)\n","\n","print(f\"Dataset Cargado. Evaluando {len(val_dataset)} imagenes de {num_classes} clases.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7w2G5sv1LKk","executionInfo":{"status":"ok","timestamp":1769273272598,"user_tz":-60,"elapsed":2706,"user":{"displayName":"diego del rio","userId":"13207948646283268583"}},"outputId":"5dea007e-8737-4f5a-ec3d-9fa21e577672"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Cargado. Evaluando 1352 imagenes de 14 clases.\n"]}]},{"cell_type":"code","source":["#Reconstruir y cargar el modelo de 327MB\n","model = models.vit_b_16()\n","model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n","\n","if os.path.exists(Save_Path):\n","    model.load_state_dict(torch.load(Save_Path))\n","    model.to(device)\n","    model.eval()\n","    print(\"Modelo cargado existosamente desde Drive\")\n","else:\n","    print(\"No se encontrÃ³ el archivo de modelo en Drive\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QMR4ecn4w75","executionInfo":{"status":"ok","timestamp":1769273285664,"user_tz":-60,"elapsed":8243,"user":{"displayName":"diego del rio","userId":"13207948646283268583"}},"outputId":"e5a4fefc-6c74-432c-869d-a568cc8eb1b8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Modelo cargado existosamente desde Drive\n"]}]},{"cell_type":"code","source":["# Funcion de oclusion\n","def aplicar_oclusion_batch(batch_tensors, ratio=0.25):\n","  ocluded_batch = batch_tensors.clone()\n","  n, c, h, w = ocluded_batch.shape\n","  patch_size = int(h * ratio)\n","\n","  for i in range(n):\n","    y = torch.randint(0, h - patch_size, (1,))\n","    x = torch.randint(0, w - patch_size, (1,))\n","    ocluded_batch[i, :, y:y+patch_size, x:x+patch_size] = 0\n","  return ocluded_batch"],"metadata":{"id":"QhwKXik54wpH","executionInfo":{"status":"ok","timestamp":1769273489492,"user_tz":-60,"elapsed":131,"user":{"displayName":"diego del rio","userId":"13207948646283268583"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Test de estres masivo\n","niveles = [0.0, 0.25, 0.50]\n","resultados = {}\n","\n","for nivel in niveles:\n","  correctos = 0\n","  total = 0\n","  print(f\"Testing oclusion al {nivel*100:.0f}%...\")\n","\n","  with torch.no_grad():\n","    for inputs, labels in val_loader:\n","      inputs, labels = inputs.to(device), labels.to(device)\n","      if nivel > 0:\n","        inputs = aplicar_oclusion_batch(inputs, nivel)\n","\n","      outputs = model(inputs)\n","      _, preds = torch.max(outputs, 1)\n","      correctos += torch.sum(preds == labels.data)\n","      total += labels.size(0)\n","\n","  accuracy = correctos.double() / total\n","  resultados[nivel] = accuracy.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tbqND0B6wS2","executionInfo":{"status":"ok","timestamp":1769274522315,"user_tz":-60,"elapsed":45278,"user":{"displayName":"diego del rio","userId":"13207948646283268583"}},"outputId":"becd08cb-b7a3-4cf2-9775-41dc3ae29b50"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing oclusion al 0%...\n","Testing oclusion al 25%...\n","Testing oclusion al 50%...\n"]}]},{"cell_type":"code","source":["#Resultados finales para tu tests\n","print(\"\\n\" + \"=\"*30)\n","print(\"RESULTADOS DE VISIBILIDAD PARCIAL\")\n","print(\"=\"*30)\n","for nivel, acc in resultados.items():\n","  print(f\"Oclusion {nivel*100:>3.0f}% | Accuracy: {acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BO7WG4Y7uDx","executionInfo":{"status":"ok","timestamp":1769274562585,"user_tz":-60,"elapsed":123,"user":{"displayName":"diego del rio","userId":"13207948646283268583"}},"outputId":"fa1a9f9d-78aa-46ad-f8f5-a685985c1328"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==============================\n","RESULTADOS DE VISIBILIDAD PARCIAL\n","==============================\n","Oclusion   0% | Accuracy: 0.9283\n","Oclusion  25% | Accuracy: 0.9075\n","Oclusion  50% | Accuracy: 0.8550\n"]}]}]}